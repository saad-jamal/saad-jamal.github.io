<!DOCTYPE html>
<html>
<head>
	<title>Saad Jamal</title>
	<meta name="description" content="CS Student At UC Berkeley">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
	<link rel="stylesheet" type="text/css" href="styles.css">
</head>

<body>
	<div id="container">
		<h1 class="global-title">Saad Jamal</h1>
		<nav>
			<ul>
				<li><a href="http://saad-jamal.github.io">
					Home
				</a></li>
			</ul>
		</nav>

		<div class="greeting-container">
			<img src="me.jpg" alt="Saad Jamal" class="avatar">
			<p>I'm a Sophomore studying Computer Science and Applied Mathematics at U.C. Berkeley, interested in how algorithms and big data can shape public policy. My interests span civil rights, rocketry, vexillology, and computer architecture.
		</div>

		<p><br /></p>

		<ul>
		  <li><strong>Email</strong>: saad.jamal@berkeley.edu</li>
		  <li><strong>LinkedIn</strong>: <a href="https://www.linkedin.com/in/saad-jamal-39058916b/">/in/saad-jamal</a></li>
		  <li><strong>GitHub</strong>: <a href="https://github.com/saad-jamal">/saad-jamal</a></li>
		</ul>

		<p>Currently working at NASA Ames Research Center in the Human Factors Lab. In conjuction with Alaska Airlines and the FAA, I am studying whether the presence of the Flight Director (FD) on the Primary Flight Display (PFD) plays a role in the First Officer's situational awareness.</p>
		<ul>
			<li>Built a data analysis tool from the ground up to aid in evaluation of pilot performance. The application allows researchers to monitor approximately 65 key flight variables, graphical representation of the 737NG flight displays, over-the-shoulder video data, and eye-tracking synchronized in real time</li>
			<li>Conducting data analysis to determine changes in scanning and eye fixation patterns in the approach phase of flight. Utilized Python Pandas and Matlab for processing, cleaning and statistical analysis.</li>
			<li>Building a pipeline to automatically clean and re-adjust frames of reference of eye-tracking data. This should hopefully improve the accuracy of current eye-tracking data and improve research outcomes.</li>
		</ul>

		<p>In addition, serving as a research assistant at the California Partners For Advanced Transportation Technology. Working alongside the Connected Corridors team on a project for Caltrans to explore the application of machine learning techniques to improve quality of management decisions.</p>
		<ul>
			<li>Using Python Pandas, Sci-Kit Learn, and AWS Buckets to collect, clean, and pre-process data, conduct feature
			extraction, and identify misconfigured sensors on the ground. Unsupervised learning techniques will be applied on
			District 7 data to detect anomalies.</li>
			<li>Final product will be displayed in a visualization dashboard built using React and Node.</li>
		</ul>

		<p>Serving as a National Open Source Developer for the Red Cross. Working alongside Intel's AI Lab to use natural language processing tools to improve disaster relief.</p>
		<ul>
			<li>Leveraging the strong volunteer support of the Red Cross, the final product will record notes and text data from volunteers about the situation on the ground. It will then classify the notes according to a given category, i.e. 'Health', 'Education', 'Sanitation', etc. Sentiment analysis will be used to determine a clearer picture of the situation on the ground.</li>
			<li>Researching ways to build an offline version of <a href="https://www.mapillary.com/app/?lat=15.578693403491485&lng=-61.45180972222221&z=17&pKey=VOQUWBZFcEscdMVRgIZnfQ">Mappillary</a>, i.e. an application you could upload street level images to and then browse via a simple map interface.</li>
		</ul>

		<p>Am a Course Tutor for CS61b: Data Structures. Facilitate class operations by assisting students in lab/office hours, grading homework, writing course material, and leading topical review sessions.</p>
	</div>


</body>
</html>